{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries and Set Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables from the .env in the local environment\n",
    "load_dotenv()\n",
    "\n",
    "nyt_api_key = os.getenv(\"NYT_API_KEY\")\n",
    "tmdb_api_key = os.getenv(\"TMDB_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the New York Times API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.nytimes.com/svc/search/v2/articlesearch.json?api-key=FKHaGic29nkCal3OLpJo5i0GchhbQLm8&begin_date=20130101&end_date=20230531&fq=section_name:\"Movies\" AND type_of_material:\"Review\" AND headline:\"love\"&sort=newest&fl=headline,web_url,snippet,source,keywords,pub_date,byline,word_count&page=0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the base URL\n",
    "nyt_url = \"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "tmdb_url = \"https://api.themoviedb.org/3/search/movie?\"\n",
    "\n",
    "# Filter for movie reviews with \"love\" in the headline\n",
    "# section_name should be \"Movies\"\n",
    "# type_of_material should be \"Review\"\n",
    "# Use a sort filter, sort by newest\n",
    "# Select the following fields to return:\n",
    "# headline, web_url, snippet, source, keywords, pub_date, byline, word_count\n",
    "nyt_field_list = \"headline,web_url,snippet,source,keywords,pub_date,byline,word_count\"\n",
    "\n",
    "# Search for reviews published between a begin and end date\n",
    "begin_date = \"20130101\"\n",
    "end_date = \"20230531\"\n",
    "\n",
    "# Refine your search - note that these are specific to NY Times\n",
    "\n",
    "# Filters - Technology and Special Report\n",
    "nyt_filter_query = 'section_name:\"Movies\" AND type_of_material:\"Review\" AND headline:\"love\"'\n",
    "\n",
    "# Sort - newest\n",
    "sort = \"newest\"\n",
    "\n",
    "# Page number\n",
    "page_number = 0\n",
    "\n",
    "# Build NYT URL\n",
    "# Build URL - The f-string has been split in multiple lines to make is easier to understand\n",
    "query_url = (\n",
    "    f'{nyt_url}' +\n",
    "    f'api-key={nyt_api_key}' +\n",
    "    f'&begin_date={begin_date}' +\n",
    "    f'&end_date={end_date}' +\n",
    "    f'&fq={nyt_filter_query}' + \n",
    "    f'&sort={sort}' +\n",
    "    f'&fl={nyt_field_list}' +\n",
    "    f'&page={str(page_number)}'\n",
    ")\n",
    "query_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved page 0\n",
      "Retrieved page 1\n",
      "Retrieved page 2\n",
      "Retrieved page 3\n",
      "Retrieved page 4\n",
      "Retrieved page 5\n",
      "Retrieved page 6\n",
      "Retrieved page 7\n",
      "Retrieved page 8\n",
      "Retrieved page 9\n",
      "Retrieved page 10\n",
      "Retrieved page 11\n",
      "Retrieved page 12\n",
      "Retrieved page 13\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the reviews\n",
    "reviews_list = []\n",
    "\n",
    "# Loop through pages 0-19\n",
    "for page in range(20):\n",
    "    # Create query with a page number\n",
    "    #API results show 10 articles at a time\n",
    "    # Make a \"GET\" request and retrieve the JSON\n",
    "    nyt_response = requests.get(query_url).json()\n",
    "\n",
    "    # Add a twelve second interval between queries to stay within API query limits\n",
    "    time.sleep(12)\n",
    "\n",
    "    # Try and save the reviews to the reviews_list\n",
    "    try:\n",
    "        # Loop through the reviews[\"response\"][\"docs\"] and append each review to the list\n",
    "        for review in nyt_response[\"response\"][\"docs\"]:\n",
    "            reviews_list.append(review)\n",
    "\n",
    "        # Print the page that was just retrieved\n",
    "        print(f\"Retrieved page {page}\")\n",
    "    except:\n",
    "        # Print the page number that had no results then break from the loop\n",
    "        print(f\"No results found on page {page}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n",
    "\n",
    "print(json.dumps(reviews_list[:5], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of reviews to a pandas dataframe using normalize\n",
    "#nyt_df = pd.DataFrame(reviews_list)\n",
    "nyt_df = pd.json_normalize(reviews_list)\n",
    "nyt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the title from the \"headline.main\" column and\n",
    "# save it to a new column \"title\"\n",
    "# Title is between unicode characters \\u2018 and \\u2019. \n",
    "# End string should include \" Review\" to avoid cutting title early\n",
    "nyt_df['title'] = nyt_df['headline.main'].str.extract(r'\\u2018(.*?)\\u2019 Review')\n",
    "nyt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract 'name' and 'value' from items in \"keywords\" column\n",
    "def extract_keywords(keyword_list):\n",
    "    extracted_keywords = \"\"\n",
    "    for item in keyword_list:\n",
    "        # Extract 'name' and 'value'\n",
    "        keyword = f\"{item['name']}: {item['value']};\" \n",
    "        # Append the keyword item to the extracted_keywords list\n",
    "        extracted_keywords += keyword\n",
    "    return extracted_keywords\n",
    "\n",
    "# Fix the \"keywords\" column by converting cells from a list to a string\n",
    "nyt_df['keywords'] = nyt_df['keywords'].apply(extract_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a list from the \"title\" column using to_list()\n",
    "# These titles will be used in the query for The Movie Database\n",
    "\n",
    "titles = nyt_df['title'].to_list()\n",
    "\n",
    "# Print the title list\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access The Movie Database API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare The Movie Database query\n",
    "url = \"https://api.themoviedb.org/3/search/movie?query=\"\n",
    "tmdb_key_string = \"&api_key=\" + tmdb_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the results\n",
    "\n",
    "\n",
    "# Create a request counter to sleep the requests after a multiple\n",
    "# of 50 requests\n",
    "\n",
    "\n",
    "# Loop through the titles\n",
    "\n",
    "    # Check if we need to sleep before making a request\n",
    "\n",
    "\n",
    "    # Add 1 to the request counter\n",
    "\n",
    "    \n",
    "    # Perform a \"GET\" request for The Movie Database\n",
    "\n",
    "\n",
    "    # Include a try clause to search for the full movie details.\n",
    "    # Use the except clause to print out a statement if a movie\n",
    "    # is not found.\n",
    "\n",
    "        # Get movie id\n",
    "\n",
    "\n",
    "        # Make a request for a the full movie details\n",
    "\n",
    "\n",
    "        # Execute \"GET\" request with url\n",
    "\n",
    "        \n",
    "        # Extract the genre names into a list\n",
    "\n",
    "\n",
    "        # Extract the spoken_languages' English name into a list\n",
    "\n",
    "\n",
    "        # Extract the production_countries' name into a list\n",
    "\n",
    "\n",
    "        # Add the relevant data to a dictionary and\n",
    "        # append it to the tmdb_movies_list list\n",
    "\n",
    "        \n",
    "        # Print out the title that was found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the first 5 results in JSON format\n",
    "# Use json.dumps with argument indent=4 to format data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results to a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and Clean the Data for Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge the New York Times reviews and TMDB DataFrames on title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove list brackets and quotation marks on the columns containing lists\n",
    "# Create a list of the columns that need fixing\n",
    "\n",
    "\n",
    "# Create a list of characters to remove\n",
    "\n",
    "\n",
    "# Loop through the list of columns to fix\n",
    "\n",
    "    # Convert the column to type 'str'\n",
    "\n",
    "\n",
    "    # Loop through characters to remove\n",
    "\n",
    "\n",
    "# Display the fixed DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop \"byline.person\" column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete duplicate rows and reset index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to CSV without the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
